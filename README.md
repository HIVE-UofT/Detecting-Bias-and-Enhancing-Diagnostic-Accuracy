# Detecting-Bias-and-Enhancing-Diagnostic-Accuracy 
## Introduction
Welcome to the GitHub repository for our paper, "Detecting Bias and Enhancing Diagnostic Accuracy in Large Language Models for Healthcare Communication". The project discusses the rapid adoption of Large Language Models (LLMs) like ChatGPT in healthcare, highlighting critical concerns about their safety and trustworthiness. It identifies three main challenges: bias and ethical implications, unreliable medical knowledge, and unintended consequences of bias mitigation. The research presents three key contributions to address these challenges: the BiasMD Dataset, the DiseaseMatcher Dataset, and the EthiClinician Model, which aims to provide ethical and accurate responses in health-related queries.

## Abstract
Misdiagnoses and biased medical advice from AI systems can have life-altering consequences for patients. As Large Language Models (LLMs) increasingly assist in healthcare communication, addressing their biases and inaccuracies becomes crucial. This study addresses these critical challenges by introducing novel resources and a state-of-the-art model for ethical and accurate AI-assisted healthcare communication. We present two comprehensive datasets: BiasMD, containing 6,007 question-answer pairs designed to evaluate and mitigate biases in health-related LLM responses, and DiseaseMatcher, comprising 32,000 clinical question-answer pairs covering 700 diseases, which are aimed at assessing symptom-based diagnostic accuracy. Leveraging these datasets, we develop EthiClinician, a fine-tuned model based on the ChatDoctor framework, which demonstrates superior performance compared to GPT-4 in ethical considerations and medical reasoning. Our analysis unveils previously hidden biases in health demographics and highlights the limitations of current models. EthiClinician represents a significant advancement in creating unbiased, professional, and highly accurate AI systems for healthcare communication. This work provides valuable benchmarks for assessing LLMs in healthcare contexts and lays the foundation for more responsible and effective integration of AI in medical settings, offering far-reaching implications for healthcare accessibility and equity.
## Contributions
Our key contributions in this work are threefold:

1. **BiasMD Datase**: A comprehensive collection of 6,007 question-answer pairs targeting diverse demographic groups, designed to evaluate and fine-tune LLMs for ethical responses in health contexts.
2. **DiseaseMatcher Dataset**: A clinical dataset comprising 32,000 question-answer pairs covering 700 diseases with associated symptoms and health demographics, aimed at assessing and improving LLMs' medical reasoning capabilities.
3. **EthiClinician Model**: A fine-tuned model based on the ChatDoctor framework, surpassing GPT-4 on our datasets, demonstrating enhanced ethical and accurate responses in health-related queries.
## BiasMD Overiew
![BiasMD (5)](https://github.com/user-attachments/assets/1504e999-7a03-4460-9216-b1e036d2e442)

## DiseaseMatcher Overiew
![BiasMD (6)](https://github.com/user-attachments/assets/887f0d79-3f7d-4ab0-9b26-0e9c1f8197ec)

## DiseaseDecipher Overiew
![BiasMD (13)](https://github.com/user-attachments/assets/037b370c-c74a-4517-b087-dc80854e6ab3)
